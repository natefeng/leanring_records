多线程学习 最全的
volatile
voliatile保证了线程与线程之间的可见性

并发的三大特性 可见性 原子性 有序性#多线程学习 最全的

# volatile

voliatile保证了线程与线程之间的可见性

并发的三大特性 可见性 原子性 有序性

voliatile 实现了线程的可见性和有序性

可见性是因为jvm对处理器发了一条Lock前缀的指令

转变成汇编即可看到代码

Lock前缀的指令有两个作用

**将当前处理器的缓存行数据写回到内存**

**使其他处理器缓存行相同的数据失效**

解决方法 缓存一致性协议 MESI 

volatile可以禁止指令重排

 

## volatile的使用和优化

一个对象的引用占用4个字节

手写JUC包的并发大师**Doug lea**在jdk7的并发包新增了一个类

**LinkedTransferQueue** 

里面的头尾结点多定义了15个对象的变量

为什么呢？ 因为一个字节占用4个字节 15个占用60 加上volatile修饰的value刚好64字节  而英特尔高速缓存行是64个字节宽

缓存行每次加载数据的时候 会一次性加载64个字节 有可能把头尾 head tail加载到一个缓存行 

这样可以使得头尾结点可以不在一个缓存行里面 因为队列会频繁的更换头尾节点

如果当一个处理器修改该缓存行里面的头节点是 会使其他处理器无法修改该缓存行的尾节点 会导致性能大大降低

不保证数据的原子性

i++ 该操作分为3步  读 加1 写  如果是volatile

那么 就是  

```java
load 
increment
store
storeloadBarrier    
```

执行到该屏障才会保证所有线程看到最新的值

如果A线程先读i变量 然后此时切换到B线程  B线程读到了i变量并且进行加1 写入 但是还没有执行到第四步 此时又切换到线程A 此时线程A也拿着之前的数据自增 那么线程A刷入主内存为+1 线程b也是加1 没有实现原子性的+2操作

## java对象头

java对线存储在堆  大致可分为三部分 

对象头 对象体  对齐字节

对象头中的mark Word表示当前对象的线程锁组状态，另外还可以配合GC存放该对象的hashCode

ClassWord是一个指向方法区class信息的指针，意味这该对象可随时知道自己是哪个Class的实例

对象体是保存对象的属性和值的主题部分

**偏向锁** : 偏向第一个访问锁的线程 如果期间该锁没有被其他的线程访问 则持有偏向锁的线程将不需要触发同步

## 锁的升级过程

我们通常说的synchronized实现的的同步锁，真名叫做重量级锁 重量级锁会造成线程排队(即串行) 会导致操作系统频繁的在用户态和核心态之间来回切换 造成代价高效率低

jdk1.6以后的改进  JVM不会直接使用重量级锁 引入了偏向锁和轻量级锁

初期锁对象刚创建的时候，此时对象头的mark word 的锁标志位初始化为01 偏向锁标识为0 为无锁状态

当第一个线程访问该锁时 jvm会偏向第一个线程 即为偏向锁 将偏向锁标志位改成1  如果期间没有其他线程访问该锁 那么该线程访问该锁不需要触发同步机制 大大提升了效率  mark word 记录该线程的id

jvm撤销偏向锁需要等待全局安全点 （也就是此使没有任何执行的字节码文件）

当其他线程访问时 jvm进行锁升级 升级为轻量级锁   哪个线程先占有对象就先执行代码 

轻量级锁一般分为**自旋锁**和**自适应自旋锁**

自旋就是不会阻塞 即在原地循环等待 直到那个获得锁的线程释放锁以后这个线程马上可以获得锁 

注意：锁在原地循环的时候是ch会消耗cpu的 相当于一个什么都没有的for循环

 并且轻量级锁需要保证同步代码块的代码执行很快的场景 

经验表明 大部分同步代码块执行的时间都很短 因此才有了轻量级锁

当大量线程的时候 jvm升级为重量级锁  实现同步 底层是指向一个对象监视器对象

使用集合来管理其他的线程      

IdentityEventExecutorGroup  IoThreadPool 

# synchronized 原理

同步代码块

synchronized反编译后查看对应的字节码 可以发现通过monitorenter和monitorexit实现的

每个对象都有一个monitor 也就是监视器锁 当monitor被占用就表示对象处于锁定状态  monitorenter的作用就是获取monitor的所有权  

monitorexit是释放monitor的所有权

1.大致步骤 

 当monitor的进入数为0时 则线程进入到monitor 将monitor 加1  该线程为monitor的所有者

如果此时该线程已经拥有monitor 再次进入时 会再将monitor加1 即可重入锁 用完之后monitorexit释放 monitor进入数减1

当其他线程进入时，发现不为零 则阻塞 直到该monitor的进入数为0 

同步方法

ACC_SYNCHRONIZED  有这个标识的话需要先获取monitor对象 同一时刻只能有一个线程拥有该对象

同步代码块需要jvm去显式的去获取和释放monitor来实现同步

而monitor底层依赖于操作系统的**mutex**互斥原语 

https://baijiahao.baidu.com/s?id=1648077822185803003&wfr=spider&for=pc  ABA问题演示以及解决

![img](https://oscimg.oschina.net/oscnet/2bcc8161c52eb100d2c7c4c96c70d3c5823.jpg)

# 轻量级锁

无锁状态升级为轻量级锁的过程：向当前线程栈帧插入一条锁记录，里面的锁引用字段指向锁对象

并且将锁对象的无锁状态的markWord复制一份，官方称为displacemarkword,并且将displacemarkword保存到锁记录中的displace字段中，

并且cas操作修改锁对象的高位markword的bit位，让其指向当前线程，并且修改markword的锁状态位，也就是将01修改为00

当进行锁重入的时候，也会先插入一条锁记录，里面的锁引用字段指向当前锁对象

同时也复制一份无锁状态的markword，并且保存到displace字段中，并且使用cas操作区修改markword的锁状态位，但是这次会失败，因为它使用的值是将01改为00，但是此时的标志位已经是01，所以失败，失败后会检查为什么失败，具体操作就是看markword高位的bit位的值是不是代表指向当前线程锁空间，如果是，则代表一次锁重入，并且将displace字段置为空

释放轻量级锁的过程，找到当前线程栈中找到最后一条 锁引用字段指向当前锁对象的锁记录，将锁记录中的锁引用字段设置为null，然后判断此时锁记录中的dispace字段是不是为null，如果是则代表是为重入锁的释放，所以只需要把锁记录字段设置为Null即可，代表锁被重入之后的一次退出，如果displaced字段不是Null，则代表要完全释放锁，则会通过CAS的方式，将锁对象的Markword替换为displacedmarkword，如果成功，则代表完成锁的释放，如果失败，则代表可能已经被升级到重量级锁或者已经正在处于膨胀状态中了，需要走重量级锁的退出逻辑

# 偏向锁升级轻量级锁过程

如果线程A持有偏向锁，并且锁对象的markword是指向线程A的偏向线程ID，此时如果线程B需要持有锁，那么会首先向当前栈中插入一条锁记录，检查锁记录，如果发现此时是处于偏向锁状态也不是自己的线程,那么会提交一个撤销偏向锁的任务，这个任务被提交到了VM线程的任务队列中，VM线程会不停的拿出任务，判断是不是需要等到safepoint去执行，safepoint需要暂停用户程序，VM此时运行，通过会做一些比如FULL GC，撤销偏向锁的任务等等，撤销偏向锁需要在安全点内执行，为什么呢？ 因为可能会产生并发问题，因为撤销偏向锁需要修改当前线程栈中的数据，存在并发问题，安全点内，除了VM线程其他线程都处于阻塞状态，撤销偏向锁任务首先需要去检查当前JVM所有存活线程，主要是为了检查当前持有偏向锁的线程是否还存活，因为前面已经谈过，再进行偏向锁退出的时候，并不会将锁对象的偏向状态给恢复，就算完全退出后，仍然保留偏向状态，如果持有偏向锁线程已经消亡，那么会直接将markword改位无锁状态或者匿名偏向锁状态，大部分情况下是修改为无锁状态，如果偏向锁线程没有消亡，需要判断偏向锁线程是不是还在同步代码块之内，通过遍历偏向锁栈内的锁记录来判断，如果栈内有一条锁记录的锁字段引用指向锁对象的话，那么就说明偏向线程仍然处于同步代码块以内。因为在释放偏向锁线程的时候，偏向锁线程做的事情是把锁记录中的锁引用字段设置为Null，如果发现没有处于同步代码块内，处理方式和消亡一样，

如果处于同步代码块内，那么此时就需要偏向锁到轻量级锁的升级，首先会拿到偏向线程的栈中第一条锁记录，然后复制一份锁对象无锁的markword,然后将该值保存到displaced中，同时使用cas去修改锁对象的状态标识，此时就算已经完成了锁对象的升级过程，并且保留这条锁记录的内存地址，其实也就是持锁线程空间中的某一个位置用于判断轻量级锁指向哪个线程。此时修改完成以后呢，外部线程就自旋等待内部偏向锁线程执行完同步代码块，执行完了以后呢偏向线程此时升级为了轻量级锁，轻量级锁执行完以后会将markword标志位修改为无锁，此时外部线程再去获取该锁，通过一样的逻辑

**偏向锁获取流程，首先判断是不是匿名偏向状态，也就是Markword高位内bit位是不是为0，如果是并且也是匿名偏向状态，则使用cas将markword高位内修改为当前线程id**，并且向当前线程栈内插入一条锁记录

如果偏向锁重入，则会首先判断Markword线程ID是不是当前线程ID，如果是，则会插入一条dispaced为空的锁记录用来标识锁重入

最本质的区别，轻量级锁的完全释放需要cas替换将锁对象的markword替换为displaced里面存放的displacedmarkword值，修改为无锁状态，

偏向锁的加锁需要cas修改线程id,并且需要添加一条锁记录，锁引用字段指向锁对象，释放的话则不会cas修改，只会删除对应的锁记录

# 轻量级锁升级重量级锁

锁膨胀到重量级锁一般有3种场景，一种是调用轻量级或者偏向锁的hashCode方法，因为轻量级锁和偏向锁没有办法存储锁对象的hashCode值，所以会导致膨胀为重量级锁，在ObjectMonitor管程对象中保存HashCode

一种是调用线程的wait()方法，因为轻量级锁和重量级锁没有队列，而重量锁管程对象有三个队列，一个竞争队列一个EntrySet队列，一个WaitSett队列，会将线程包装成一个Waiter结点放入WaitList队列中，等待其他的线程使用notify或者notifyall方法来唤醒等待的线程(wait会释放锁)

**Object Monitor的数据结构：**

**owner ：表示此时哪个线程占有锁**

**recursions ：线程的重入次数**

**WaitSet：等待线程组成的双向循环链表**

**EntryList ：阻塞线程进入的结点**

还有一种就是锁竞争导致的，会导致膨胀为重量级锁

当出现竞争是，首先比如说此时是轻量级锁状态，首先假设Thread1获取锁，Thread2竞争锁，就会膨胀，初始化Object Monitor对象，并且将锁对象的mark word修改为重量级锁状态和指向Object Monitor的管程对象，此时Thread1尝试去cas修改MarkWord会失败，因为此时已经不是使用自己的栈帧了，然后自旋等待Thread2膨胀完成

# java内存模型

## 线程之间通信

线程之间通信一般有两种  即 共享内存和消息传递

java里面采用的是共享内存 即一段代码只能一个线程使用  所以线程与线程之间进行了隐式通信

java线程通信由java内存模型(JMM)控制

JMM定义了线程与主内存之间的抽象关系 即每个线程都有一个本地内存 线程的本地内存只是一个抽象 实际上不存在 

 每个本地内存里面保存了主内存共享数据的副本 读/写

## 内存可见性问题

两个线程之间可能会出现内存可见性问题 为什么呢

因为执行程序时，编译器和处理器会对指令进行重排序。 

编译器级别的重排序是指在不改变代码语义的情况下，可以重新安排语句的顺序。

处理器的重排序分为两种

一种是  指令级并行的重排序  指现代处理器可以将多条指令重叠执行  处理器可以改变语句对应机器指令的执行顺序

另外一种是 内存系统的重排序  由于处理器使用读/写缓冲区，这使得加载和存储看起来像是乱序执行  

对于编译器 JMM的编译器重排序规则会禁止特定类型的编译器重排序

对于处理器而言java编译器在生成指令之前 插入特定类型的内存屏障 通过内存屏障来禁止特定类型的重排序

## 内存屏障

![image-20201109180631980](D:\学习笔记\image-20201109180631980.png)



处理器重排可能出现的内存可见性问题

首先处理器A读a为0 处理器b读b为0

然后处理器A将a=1写入到写缓冲区里面

此使内存a还是为0

处理器B读a有可能为0

这样会导致内存可见性问题

由于写缓冲区没有及时刷新导致	

内存屏障分为四大类

LoadLoad Barriers  确保装载load1的数据在于load2之前

StoreStore Barriers  确保store数据对其他处理器可见(刷新到内存)并且先于store2的所有后续存储指令的存储

LoadStore Barriers  确保装载load1的数据装载先于Store2及后续的存储指令刷新到内存

StoreLoad Barriers  确保Store1数据对其他处理器可见(刷新到内存)并且先于Load数据装载之前

StoreLoad 开销最大 因为他会把处理器缓冲区中的数据全部刷新到内存中

read 作用于主内存 把主内存的值传递到线程的私有本地内存

Load作用于工作内存 把read的值放入私有本地内存的变量副本里面

use：作用于工作内存 把工作内存变量副本的值传输给执行引擎

assign 作用于工作内存 把从一个执行引擎的值赋值给工作内存的变量

store 作用于工作内存 把工作内存一个变量的值传输到主内存

write：作用于主内存 把工作变量传来的值赋值给主内存中的变量

**volatile为什么可以保持内存可见性呢**？

因为volatile的特殊规则是

 read,load,use动作必须是连续出现的

 assign,store,write动作必须是连续出现的

所以volatile变量能够

每次读取前先从内存读取最新的值

每次写入后立刻同步到主内存

```java
class Singleton {
    private static Singleton instance;
    
    public int f1 = 1;   // 触发部分初始化问题
    public int f2 = 2;
    	
    private Singleton(){}
	
    public static Singleton getInstance() {
        if (instance == null) { // 当instance不为null时，可能指向一个“被部分初始化的对象”
            synchronized (Singleton.class) {
                if ( instance == null ) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```



上面的代码看起来似乎完美 即减少了阻塞，又解决了竞态条件  但是也会出现问题

DCL机制

但是 问题在于  instance = new Singleton();

 该操作不是原子操作

此操作大概有三步

1.分配对象的内存空间

2.初始化对象(对f1,f2进行初始化)

3.将instance 指向 内存空间

此操作 2依赖于1 3不依赖于2 

此使另外一个线程getInstance 可能获得一个未被初始化完成的单例

voliatile标记可以解决编辑器层面的可见性和重排序问题 

内存屏障解决了硬件层面的可见性和重排序问题

## java并发队列

![image-20201110163819289](D:\学习笔记\image-20201110163819289.png)

线上环境无界队列排除 数组空间连续 所以排序有界的LinkedBlockingQueue

选择数组队列

因为数组地址空间是连续的 处理器会优化 例如处理器缓存行

但是ArrayBlockingQueue太慢了

但是为什么会说处理器会优化数组呢

因为处理器现在都有高级缓存 缓存的速度是远比内存快的  缓存一般以缓存行来保存数据 每个缓存行64个字节 java中long 8个字节 比如说缓存行加载一个long类型变量的时候 会直接再加载7个 

## 数据依赖性

如果两个操作存在数据依赖性 

那么编译器和处理器不会进行重排序(注意：仅限单线程而言)

happens-before规则

**as-if-serial语义** 

**这句话的意思是不管怎么重排序(编译器和处理器为了提高并行度) 单线程的执行结果不能被改变**

都要遵守as-if-serial语义 所以都不会对存在数据依赖关系的操作做重排序

## 顺序一致性

如果程序是正确同步的 程序的执行将具有顺序一致性

即程序的执行结果与该程序在顺序一致性内存模型中的执行结构相同

这里的同步指广义上的同步 包括对锁,volatile和final的使用

顺序一致性内存模型是一个理论参考模型 通常处理器和编程语言的内存模型会以顺序一致性内存模型作为参

## 顺序一致性内存模型

顺序一致性内存模型是这么定义的 

1）一个线程中的所有操作都必须按程序的顺序来执行

2）不管是否同步，在顺序一致性内存模型中，每个操作都必须以原子的方式执行并且立刻对所有线程可见

![image-20201112172714300](D:\学习笔记\image-20201112172714300.png)

可以看出线程A整体来说程序的运行顺序不变

线程B也是如此

未同步的程序在顺序一致性内存模型上来说整体上不是有序的

但所有线程都只能看到一个一致的整体执行顺序

但是JMM就没有这个保证 未同步程序在jmm里面不但整体的执行顺序是无序的 所有线程也可能看到不一致的执行顺序

假设当前线程把数据存入缓存 还没刷新到主存 此使该数据只对当前线程有效

![image-20201112173327514](D:\学习笔记\image-20201112173327514.png)

在JSR-133内存模型之后(jdk5之前)仅仅允许把64位的写操作拆分成两个32位

读操作必须具有原子性 

处理器和内存之间的数据传递都是通过总线 是经过一系列步骤的

这一系列步骤称为总线事务 是原子性的操作处理器主要是以该方式来实现原子操作的

## volatile的内存语义

锁的happens-before规则能保证获取锁和释放锁的两个线程具有可见性

即读volatile变量之前，可以看到所有线程对该变量的写入

锁的语义决定了临界区代码的执行具有原子性

即monitorenter到monitorexit之间具有原子性

那么即对voliatile的读写操作具有原子性

但是在多重复合操作上整体看不具有原子性操作

ModelOpenManager.getInstance().isOpen()

**volatile的写语义：当写一个voliatile变量时，JMM会把该线程对应的本地内存的共享变量值刷新回主内存**

**volatile的读语义：当读一个voliatile变强时，JMM会使该线程对应的本地内存置为无效，让其重新去主内存读**

**当线程A写一个变量，实际上是线程A向接下来要读这个voliatile变量的某个线程发送的消息(发送我修改了该变量的消息)**

**当线程B读一个变量，实际上是线程B接受了之前来自某个线程所发送的消息(某个线程对该变量的修改)**

**当线程A写入变量线程B读入变量 实际上是线程A通过主内存向线程B发送消息**



![image-20201113174405422](D:\学习笔记\image-20201113174405422.png)

当第一个操作是对voliatile变量的读是 不管第二个变量是普通读写还是voliatile读还是voliatile写 都不允许重排序 这个规则保证对voliatile的读之后的操作不会发生在读之前

### volatile内存语义的实现

JMM的内存屏障插入策略是保守的 采用如下策略

1.在每个volatile写操作前面插入一个StoreStore屏障

2.在每个volatile写操作的后面插入一个StoreLoad屏障

3.在每个volatile读操作的前面插入一个LoadLoad 屏障

4.在每个volatile读操作的后面插入一个LoadStore屏障

volatile常见的使用模式是：

 一个线程去写volatile变量，多个线程去读变量

如果在读操作之前加StoreLoad屏障会导致性能不如在一个写操作之后加StoreLoad屏障 

因为一个是只有一个线程慢 如果读操作之前都有 多个线程都要加屏障 会导致效率问题

![image-20201116110205817](D:\学习笔记\image-20201116110205817.png)

![image-20201116110229265](D:\学习笔记\image-20201116110229265.png)

根据下面的代码会进行在指定的地方插入指定的内存屏障

在最后一个volatile必须插入StoreLoad屏障 因为该代码直接就return了 编译器不知道后面的代码会不会出现读写操作 所以为了安全 会插入该全能屏障

X86机器不会对读读 读写和写写做重排序

![image-20201116111134717](D:\学习笔记\image-20201116111134717.png)

## 锁的内存语义

### 锁的释放和获取的内存语义

当线程释放锁后 JMM会把线程对应的本地内存的共享变量刷新到主内存中。

当线程获取锁后 JMM会把本地内存置为无效，从而使得临界区保护的临界区代码必须从主内存中读取变量

锁只要保持一段临界区 而volatile保护的时候临界区里面的代码对volatile的读写制定一定的规则 在相应的规则插入相应的内存屏障来保证临界区里面的代码不会进行重排序

而且volatile实现了对单个volatile变量的读/写具有原子性

``` java
class ReentrantLockExample{
     int a = 0;
    ReentrantLock lock = new ReentrantLock();
    public void writer(){
        lock.lock;
        try{
            a++;
        }finally{
            lock.unlock;
        }
    }
    public void reader(){
        lock.lock();
        try{
            int i = a;
            .....
          }finally{
            lock.unlock();
        }
    }
}
```

ReentrantLock的实现依赖于java同步框架 AbstractQueuedSynchronizer(AQS)

AQS使用的是一个整型的volatile变量(命令为state)来维护同步状态

非公平锁的加锁

![image-20201116144856229](D:\学习笔记\image-20201116144856229.png)

该操作以CAS方式来更新值 



该操作具有和volatile相同的内存语义	

![image-20201116150636067](D:\学习笔记\image-20201116150636067.png)

os::is_MP(); // 代表是否为多核心处理器

mov edx,dest 为volatile该变量的地址 evx 为新值 eax为比较的值

如果mp多核心 就为cmpxchg增加Lock指令 否则不增加  然后用比较edx地址里面的值和eax比较 如果 则[edx] = ecx; 否则 不操作

cmpxchg 比较并替换 汇编指令	

**intel的手册对Lock前缀的说明如下**

**1）确保对内存的原子操作** 

**该操作会锁住总线 使得其他处理器无法通过总线访问内存  但是这会带来性能的降低和昂贵的开销  从pentium4开始 增加了缓存行锁定 来保证指令执行的原子性**

**2）把写缓冲区的所有数据的所有数据刷新到内存**

**3）禁止该指令，与之前和之后的读和写指令重排序**

JAVA的CAS会是使用现代处理器提供的高效机器级别的原子指令 这些指令以原子的方式对内存 执行 读-改-写 

Concurrent的包实现

![image-20201116170808696](D:\学习笔记\image-20201116170808696.png)

## Final域的重排序规则

![image-20201116175212739](D:\学习笔记\image-20201116175212739.png)

​      在构造函数对final域的写入，与随后把该对象的引用赋值给一个引用变量 

​      该操作不能重排序

​    在初次读一个包含final域的引用 ，与随后读这个final域 该两个操作不能被重排序

![image-20201116175135528](D:\学习笔记\image-20201116175135528.png)



**由上图可知    JMM禁止编译器把 对final域的写重排序到构造函数之外**

​                      **编译器后在final域写入之后 构造函数return之前 加入一个StoreStore屏障 禁止处理器把final域的写重排序到构造函数之外**

写Final域的重排序规则可以保证，在对象被引用之前，对象的final域已经被正确的初始化过了，普通变量的写则没有保证

初次读对象引用和初次读对象引用的final域 该操作禁止重排序 

会在读final域之前插入一个loadload屏障

![image-20201116182440816](D:\学习笔记\image-20201116182440816.png)

final的域的重排序规则保证:在读一个对象的final域之前 一定会先读取该对象的引用

以上都是对于普通变量final域的写入

![image-20201116183218187](D:\学习笔记\image-20201116183218187.png)

操作1是对final域的写入

操作2是对一个final域引用的对象的成员域的写入

对于引用类型 写final域的重排序规则使得对final域引用的对象的成员域的写入和将该对象的引用赋值给一个引用变量，这两个操作之间不可以重排序

final域不保证 线程C可以看到线程B修改的数 因为存在数据竞争  如果想要看到需要加volatile修饰 或者锁

### final语义在处理器中的实现

写final域的要求规则在写final域之后构造函数返回之前插入一个StoreStore屏障

但是由于X86处理器不会对写-写操作做重排序 所以该屏障省略

读final域的要求规则在读final域之前插入一个LoadLoad屏障

但是由于X86处理器不会重排序存在间接依赖关系的操作 所以该屏障也省略

也就是在X86处理器中，final域的读/写不会插入任何内存屏障

### JSR-133为什么要增强final的语义

旧的JMM中，一个严重的问题就是线程可能会看到不同的final域 比如一个线程访问一个整型final域的值为0 过一段时间再访问变为1 因为第一次读到的是final域还未正确初始化的值 

## happens-before

happens-before是JMM最核心的概念，对于java程序员来说理解happens-before是理解JMM的关键

首先站在JMM设计者的角度来设计

 程序员希望JMM易于理解，易于编程，希望一个强内存模型来编写代码

处理器和编译器则希望JMM对它们的束缚越来越少，以便于它们可以更多的优化和提升性能

JMM设计者则综合设计

    ``` java
double pi = 3.14; //A
double r = 1.0;  //B
double area = pi*r*r; //C
    ```

对于上面代码 

 A happens-before B

B happens-before C

A happens-beforeC(happens-before规则的传递性)

对于以上代码![image-20201117105804646](D:\学习笔记\image-20201117105804646.png)

JMM分为两类 一类是会改变程序结果的重排序 一种是不会改变结果的重排序

第一种是禁止的 第二种是允许的(即是单线程程序下的正确性)

![image-20201117105904719](D:\学习笔记\image-20201117105904719.png)

### 《JSR-133:Java Memory Model and Thread Specif ication》

对happens-before关系的定义如下。

1）如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。A happens-before B 则A的执行结构一定对B可见

2）两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。

上面的1）**是JMM对程序员的承诺**。从程序员的角度来说，可以这样理解happens-before关系：如果A happens-before B，那么Java内存模型将向程序员保证——A操作的结果将对B可见，且A的执行顺序排在B之前。**注意，这只是Java内存模型向程序员做出的保证！**上面的2）**是JMM对编译器和处理器重排序的约束原则**。正如前面所言，JMM其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。JMM这么做的原因是：程序员对于这两个操作是否真的被重排序并不关心，**程序员关心的是程序执行时的语义不能被改变（即执行结果不能被改变**）。因此，happens-before关系本质上和as-if-serial语义是一回事。

as-if-serial语义和happens-before语义都是在不改变程序执行结果的前提下，尽可能的提高程序执行的并行度

## happens-before规则

1）程序顺序规则：一个线程的每个操作 happens-before 于该线程的任意后续规则

2）监视器锁规则：对一个锁的解锁 happens-before于随后对这个锁的加锁

3）volatile域规则：对一个volatile域的写 happens-before 于任意后续对这个volatile的读

4)  传递性

5）start()规则 ：在线程A里执行ThreadB.start(),那么A线程的ThreadB.start()操作happens-before于线程B的任意操作

6）join() 规则：如果线程A执行ThreadB.join()并成功返回，那么在线程B中的任意操作

happens-before 于线程A从ThreadB.join() 操作成功返回

## 双重校验锁

![image-20201117160241820](D:\学习笔记\image-20201117160241820.png)

![image-20201117160251172](D:\学习笔记\image-20201117160251172.png)

上面的三部 

分配对象的内存空间

初始化对象

设置instance指向刚分配的内存地址

这三部2 和 3 可能会重排序

![image-20201117161208485](D:\学习笔记\image-20201117161208485.png)

![image-20201117161214544](D:\学习笔记\image-20201117161214544.png)

单线程不会出现问题 因为根据java语言规范，必须保证重排序不会改变单线程的执行结果

### 基于类初始化的解决方案

**JVM在类的初始化阶段(即Class文件被加载后，线程使用之前)，会执行类的初始化操作**。在执行期间，JVM会获取一个锁。这个锁可以同步多个线程对同一个类的初始化

![image-20201117175304551](D:\学习笔记\image-20201117175304551.png)

![image-20201117175311715](D:\学习笔记\image-20201117175311715.png)

这里允许2和3重排序 但是不允许线程B看到该操作

初始化一个类，根据JAVA语言规划，发生下列任意一种操作时，类或者接口T将被初始化

1）T是一个类，并且一个T类型的实例被创建

2）T是一个类，类里面的静态方法被调用

3）T是一个类，类里面的静态变量被赋值

4）T是一个类，类里面的静态字段被使用，而且这个字段不是常量字段

JAVA语言规定 对于每一个类或者接口C都有唯一的初始化锁LC与之对应

### 类加载同步处理机制，大致步骤

分为如下5步

假设对象此使还没有初始化(初始化状态为state,state= noinitiation-tion),并且两个线程同时抢占该class对象的初始化锁

**第一步**： 线程A和线程B同时抢占class对象的初始化锁  

假设线程A抢到class对象的初始化锁，线程B阻塞等待  

线程A查看state状态 发现为未被初始化状态 然后将state置为 initializing 然后释放锁

**第二步** 然后开始使用该类中的静态字段或者给静态变量赋值或者创建实例

此使线程B获取锁，查看state状态 发现处于正在初始化状态

然后释放锁，同时线程B在对应的condition上等待正在执行初始化完成线程唤醒他

**第三步** 当线程A初始化完成再次获取锁将state置为initiailzed 然后唤醒正在阻塞的线程并且释放锁 

**第四**步 此使线程B被唤醒 尝试获取初始化锁，获取以后发现state已经被初始化完成，释放锁 

线程B的初始化处理过程完成

如下图

![image-20201117200843413](D:\学习笔记\image-20201117200843413.png)

![image-20201117200849463](D:\学习笔记\image-20201117200849463.png)

![image-20201117200922383](D:\学习笔记\image-20201117200922383.png)

![image-20201117200927967](D:\学习笔记\image-20201117200927967.png)

![image-20201117200934079](D:\学习笔记\image-20201117200934079.png)

![image-20201117201021005](D:\学习笔记\image-20201117201021005.png)

线程A在第二阶段开始初始化，并且在第三阶段的A4释放初始化锁。线程B在第四阶段的B1获取初始化锁 

根据happens-before规则

线程A初始化时的写入操作(执行类的静态初始化和初始化类中的静态字段)，线程B一定能看到

![image-20201117201319779](D:\学习笔记\image-20201117201319779.png)

通过对比基于volatile的双重检查锁定的方案和基于类初始化的方案，我们会发现基于类初始化的方案的实现代码更简洁。但基于volatile的双重检查锁定的方案有一个额外的优势：除了可以对静态字段实现延迟初始化外，还可以对实例字段实现延迟初始化。字段延迟初始化降低了初始化类或创建实例的开销，但增加了访问被延迟初始化的字段的开销。在大多数时候，正常的初始化要优于延迟初始化。如果确实需要对实例字段使用线程安全的延迟初始化，请使用上面介绍的基于volatile的延迟初始化的方案；如果确实需要对静态字段使用线程安全的延迟初始化，请使用上面介绍的基于类初始化的方案。

综上所述 

**双重检查加volatile校验锁适合于实例字段的延迟初始化**

**类初始化方案适合静态字段的延迟初始化**

上面的state状态和condition都是虚构出来的 JVM只是具体实现了类似功能

## java内存模型总结

### 内存模型

到底什么是内存模型？	为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是——内存模型。**为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。**通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。

内存模型解决并发问题主要采用两种方式：**限制处理器优化**和**使用内存屏障**

**所以，JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。目的是保证并发编程场景中的原子性、可见性和有序性**

也可以理解为，在特定的操作协议下，对特定的内存或者高速缓存进行读写访问的过程抽象，不同物理机器可以有不同的内存模型，java也可以有属于自己的内存模型

### 处理器内存模型

顺序一致性内存模型是理论参考模型，通常JMM和处理器内存模型设计会参考顺序一致性内存模型 同时JMM和处理器内存模型设计的时候可以对此模型要求放宽，因为如果完全按照顺序一致性内存模型来设计 那么很多的处理器和编译器优化都要被禁止，这对执行性能有很大影响

处理器内存模型划分为以下几种

​          放松程序的写-读操作的顺序 Toal Store Ordering 简称TSO内存模型

​         在上面基础上继续放松程序的 写-写操作的顺序 简称 PSO 内存模型

​       在上面继续放宽程序的  读-写 读-读 操作的顺序 简称RMO和PowerPC内存模型



注意以上的放松都是不存在数据依赖关系的

型。注意，这里处理器对读/写操作的放松，是以两个操作之间不存在数据依赖性为前提的（因为处理器要遵守as-if-serial语义，处理器不会对存在数据依赖性的两个内存操作做重排序）

因为要遵守as-if-serial

![image-20201118100917933](D:\学习笔记\image-20201118100917933.png)

由于常见的处理器内存模型比JMM内存模型要弱 所以java编译器在生成字节码时会在指定的适当位置插入对应的内存屏障来限制处理器重排序

上图由上到下内存模型由强到弱

以下是JMM针对各种不同处理器的内存模型插入不同的屏障示意图

![image-20201118101346860](D:\学习笔记\image-20201118101346860.png)

![image-20201118101610137](D:\学习笔记\image-20201118101610137.png)

最小性安全保障和64未数据的非原子性写不矛盾 

最小性安全保障是指保证对象默认初始化之后(被赋默认值)后才会被任意线程使用

非原子性写是指线程A写入一个64位变量只写了一半还没写完 但是线程B读到了线程A写入的一半，读到的是无效值

最小性安全保障保障的是读取到的值要么是默认值，要么是线程之前写入的值，并不保证线程读取到的值是之前线程写完后的值 也可以是写到一半

### JAVA内存模型

JSR-133对jdk5之前的旧内存模型的修补主要有两个

之前允许volatile变量和普通变量重排序  修补以后 禁止

和锁具有相同的语义

还有增强final的语义

## 锁升级过程

当线程访问同步代码块时，查看对象头的标志位是处于什么状态假设是处于无锁01 偏向锁标志位为0，然后尝试CAS修改对象头Mark World为当前线程ID并且把偏向锁标志位改为1，修改成功后开始执行同步代码块，以后只要是该线程访问都只会看一下是否还是当前线程ID 不会加锁 

当出现竞争时，假设线程A执行同步代码块时(此使为偏向锁)，然后线程B开始竞争，首先判断对象头的mark world是不是和线程B的id一致，如果不一致尝试用CAS修改 因为此使线程A还在执行 所以会替换失败 失败后开始尝试偏向锁撤销 撤销必须等待全局安全点(也就是此使无任何字节码文件执行) 所以等待持有偏向锁的线程A等待全局安全点后然后暂停

开始升级为轻量级锁 首先在拥有偏向锁线程的栈帧里面分配锁记录

然后复制markWorld的内容到栈帧，尝试将markWorld的锁记录指针指向当前线程中的锁记录 标志位为00 此使线程B也在做同样的事情，复制一份然后让markWorld的锁记录指针指向线程B的锁记录指针 发现无法修改 开始循环等待 自旋锁  

当线程A执行完后准备释放锁时 会查看markWorld内容和帧中锁记录内容是否一致，同时检查是否Mark World的锁记录指针是否还是指向自己 如果都满足 则成功释放锁，如果不满足 则开始新竞争

假设线程A长时间阻塞 

线程B自旋一定时间后膨胀为重量级锁，也就是将markWold的锁记录指针指向为重量级锁指针monitor，将标志位改成10 然后阻塞

此使线程A释放锁的时候发现不满足 开始唤醒所有线程 然后开始竞争重量级锁

# 并发基础

## 线程的6种状态



NEW 表示线程被创建 但是还未调用start方法

RUNNABLE 运行状态 java线程将操作系统的就绪状态和运行状态统称为运行状态

Blocked 阻塞状态 阻塞于锁

Waiting 等待状态 表示线程进入等待，进入该状态表示当前线程需要其他线程做出一些特定的动作 比如 中断 通知

TIME_Waiting 等待超时状态 该状态可以在指定时间返回

TERMINATED 终止状态

![image-20201118180949754](D:\学习笔记\image-20201118180949754.png)

![image-20201118183354801](D:\学习笔记\image-20201118183354801.png)

```java
package thread;

/**
 * @program: dataStructure
 * @description:
 * @author: Mr.Feng
 * @create: 2020-11-18 18:18
 **/
public class ThreadState {
    public static void main(String[] args) {
           new Thread(new TimeWaiting(),"TimeWaitingThread").start();
           new Thread(new Waitint(),"WaitingThread").start();
           new Thread(new Blocked(),"BlockedThread-1").start();
           new Thread(new Blocked(),"BlockedThread-2").start();
    }
    static class TimeWaiting implements Runnable {
        @Override
        public void run() {
             while (true){
                 try {
                     SleepUtils.sleep(100);
                 } catch (InterruptedException e) {

                 }
             }
        }
    }
    static class Waitint implements Runnable{
        @Override
        public void run() {
            while (true){
                 synchronized (Waitint.class){
                     try {
                         Waitint.class.wait();
                     } catch (InterruptedException e) {
                         e.printStackTrace();
                     }
                 }
            }
        }
    }
    static class Blocked implements Runnable{

        @Override
        public void run() {
            synchronized (Blocked.class){
                while (true){
                    try {
                        SleepUtils.sleep(100);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }
        }
    }
}

```

![image-20201119095032148](D:\学习笔记\image-20201119095032148.png)

一般等待状态等待别人唤醒

而超时等待等待时间到然后返回到运行状态 所以超时等待一般都会添加时间

## Daemon线程

该线程为后台线程，用于程序后台调度以及支持工作的线程，并不是必不可缺的一部分。通过jvm发现程序所有的非后台线程结束就会关闭程序同时杀死所有的后台线程 

如垃圾回收线程就是Daemon线程

而且要创建Daemon线程的时候必须在线程开启之前设置Thread.setDaemon(true)

java虚拟机在退出Daemon线程时，finally快不一定执行

## java的4种引用级别

由高到低 

强引用-软引用-弱引用-虚引用

平时我们new的对象赋值给一个引用如

``` java
Object obj = new Object //引用就是强引用，在任何事件都不会被回收 哪怕内存不足抛出异常也不会回收
如果想要会收强引用
则可以用完之后将 obj = null 将引用置为null，则gc认为该对象不存在引用才会被回收
软引用如下需要一个引用包装类
String str = new String("abc") //强引用
SoftReference<String> soft = new SoftReference<>(str);
str = null;
System.gc() //通知gc回收强引用
软引用只有在内存不足的情况下才会被回收	
 ReferenceQueue<String> referenceQueue = new ReferenceQueue<>();
    String str = new String("abc");
    SoftReference<String> softReference = new SoftReference<>(str, referenceQueue);

    str = null;
    // Notify GC
    System.gc();

    System.out.println(softReference.get()); // abc

    Reference<? extends String> reference = referenceQueue.poll();
    System.out.println(reference); //null
```

弱引用可以配合引用队列来使用，垃圾收集线程会在抛出OutofMemoryError异常之之前回收弱引用 JVM则会尽可能的收集那些长时间闲置的软引用对象，对于那些刚构建的虚拟机会尽可能保留，这也是引入引用队列 ReferenceQueue的原因

弱引用则是垃圾回收线程一旦发现了该引用就会回收，不管内存是否足够都会回收他的内存，不过垃圾回收器是优先级很低的线程，不一定很快会发现这些对象

``` java
 String str = new String("abc");
    WeakReference<String> weakReference = new WeakReference<>(str);
    // 弱引用转强引用
    String strongReference = weakReference.get();
```

虚引用顾名思义，就是如同虚设一样，不决定对象的生命周期，该对象可能被任何时间回收。如果一个对象只持有虚拟引用 那么他就和没有被引用一样

虚引用必须和引用队列联合使用

该引用的作用是

程序可以判断引用队列是否已经加入了虚引用，来了解对象是否要进行垃圾回收，可以在对象回收之前采取必要的行动

``` java
String str = new String("abc");
ReferenceQueue queue = new ReferenceQueue();
PhantomReference pr = new PhantomReference(str,queue);
```

![image-20201119151156826](D:\学习笔记\image-20201119151156826.png)

每个方法都相当于一个强引用 引用堆上的 当栈退出时，垃圾回收器会回收

但是如果定义成员变量时，垃圾收集器永远不会回收

## ThreadLocal原理

每个线程都有一份自己的变量 不会被其他线程访问到

线程安全

ThreadLocal维护了一个ThreadLocalmap  key为每个线程 value为我们要输入的值 

所以相当于每个线程保存了一份自己独有的变量

内存泄漏问题： 首先因为 ThreadLocalMap里面还有一个静态内部类 为Entry对象 该类集成了弱引用的ThreadLocal
所以ThreadLocalMap的key为弱引用 value为强引用

如果ThreadLocal没有外部强引用时只有弱引用时垃圾回收器就会回收ThreadLocal

并且ThreadLocalMap的key为弱引用 所以key也会被清理掉 为NULL

为什么不用强引用key呢？ 因为如果当垃圾回收器要回收ThreadLocal时 发现ThreadLocalMap里面的key是强引用 造成永远都不会回收ThreadLocal对象 出现更严重的问题 

ThreadLocalMap已经考虑该问题，在remove，set,get 的方法下会清理key为null的记录

如果说出现内存泄漏 那就是没有继续使用set,get 或者在使用完之后没有remove掉

## 理解中断

中断可以理解为线程的一个标识符属性，表示一个线程是否被其他线程进行了中断操作

中断好比其他线程对该线程打了个招呼

suppend()方法 resume()方法 stop()方法

都不建议使用

暂停，恢复，停止 

suppend()暂停线程不会释放资源(比如锁)而是占着资源进入睡眠

stop()方法在终结一个线程时不会保证线程的资源正常释放，通常没有给予线程正常释放资源的时间

## volatile和Synchronized

![image-20201120104200527](D:\学习笔记\image-20201120104200527.png)

通过javap工具查看生成的class文件信息

![image-20201120104226204](D:\学习笔记\image-20201120104226204.png)

 同步块使用了monitorenter和monitorexit指令

同步方法则是使用ACC_SYNCHRONIZED标识

都是抢夺对象的监视器来进入代码块

![image-20201120104401561](D:\学习笔记\image-20201120104401561.png)

可以看到

如果获取监视器成功则进入同步代码块，如果失败则进入同步队列 将状态改为阻塞

当释放锁时，唤醒等待的线程

## 等待/通知机制

线程的等待/通知机制

相当于一个线程A调用了一个对象的wait()方法进入等待

另外一个线程B调用该对象的 notify()或者notify()方法进行唤醒，线程A收到通知后从wait()方法中返回继续开始操作

需要注意的细节如下：

 **使用wait(),notify(),notifyAll方法时需要先调用对象加锁**

**调用wait()方法后，线程会释放锁，从RUNNING变为WaitIng,并将当前线程放入对象的等待队列**

其他线程调用notify方法后当前线程不会立刻返回 必须等待其他线程释放对象锁后，等待线程才会获取锁返回

notify方法是将一个等待线程从等待队列中放入同步队列

notifyAll方法是将所有线程从等待队列中放入同步队列 被移动的线程从WaitIng状态变为BlockED状态

![image-20201120111554891](D:\学习笔记\image-20201120111554891.png)

在上图中，WaitThread首先获取了对象的锁，然后调用对象的wait()方法，从而放弃了锁并进入了对象的等待队列WaitQueue中，进入等待状态。由于WaitThread释放了对象的锁，NotifyThread随后获取了对象的锁，并调用对象的notify()方法，将WaitThread从WaitQueue移到SynchronizedQueue中，此时WaitThread的状态变为阻塞状态。NotifyThread释放了锁之后，WaitThread再次获取到锁并从wait()方法返回继续执行。

## 管道输入/输出流

管道输出输出流和普通I/O流和网络输入输出不同处在于 它主要用于线程之间的传输 

传输媒介为内存

``` java
PipedWriter out  = new PipedWriter();
PipedReader in  = new PipedReader();
 out.connect(in);
```

这两个为字符输入输出流

PipedOutputStream,PipedInputStream 这两个面向字节

使用前将输出流和输入流要先建立联系 否则抛出异常

# JAVA中的锁

## Lock接口

![image-20201123100154631](D:\学习笔记\image-20201123100154631.png)

![image-20201123100201045](D:\学习笔记\image-20201123100201045.png)

![image-20201123100220907](D:\学习笔记\image-20201123100220907.png)

  ## 模板设计方法

![image-20201123103900320](D:\学习笔记\image-20201123103900320.png)

抽象父类定义算法骨架 给出不变的算法方法 可能变化的方法留给子类去重写

## 队列同步器

AbstractQueueSynchronizer 同步器 AQS 通过一个int成员变量来表示同步状态 通过内置的

FIFO队列完成资源获取线程的排队工作

同步器是实现锁(也可以是任意同步组件)的关键 在锁的实现中聚合同步器

### 队列同步器的接口与示例

同步器的设计是基于模板方法的  使用者需要继承同步器并且重写指定的方法 并调用同步器的模板方法，而这些模板方法会调用使用者重写的方法

getState()：获取当前同步状态

setState():   设置当前同步状态

compareAndSetState(int expect,int update) 使用cas设置当前状态 	该方法能保证状态设置的原子性

![image-20201123104957711](D:\学习笔记\image-20201123104957711.png)

![image-20201123113646843](D:\学习笔记\image-20201123113646843.png)

同步器提供的模板方法基本分为三类：独占式，共享式和查询同步队列

to![image-20201123142623516](D:\学习笔记\image-20201123142623516.png)

同步队列的基本结构如下图

![image-20201123142900837](D:\学习笔记\image-20201123142900837.png)

![image-20201123150736248](D:\学习笔记\image-20201123150736248.png)

![image-20201123150805466](D:\学习笔记\image-20201123150805466.png)

只有头节点才能获取到同步状态 而获取完以后会唤醒后继节点 

分析了独占式获取和释放过程，做个总结：在获取同步状态时，同步器维护这一个同步队列 

如果没有获取成功 则以CAS的方式加入到队列尾部 

移出队列的条件是该节点的前驱节点是head节点 因为只有head节点是可以获取同步状态的 

当前节点尝试获取同步状态如果成功则退出 否则进入等待

release的时候释放同步状态同时会唤醒后继节点

java5之前 如果一个线程获取不到锁时，会阻塞在synchronized之外，对该线程进行中断操作  该线程的中断标识位被修改，但是线程仍然阻塞在synchronized之外，等待获取锁。

在java5之后，同步器提供了acquireInterruptibly(int arg)方法，这个方法在等待获取同时状态时，如果线程被中断，则会立刻抛出异常立刻返回![image-20201123162834557](D:\学习笔记\image-20201123162834557.png)

``` java
package thread;

import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.AbstractQueuedSynchronizer;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;

/**
 * @program: dataStructure
 * @description:
 * @author: Mr.Feng
 * @create: 2020-11-25 10:47
 **/
public class TwinsLock implements Lock {
     private  final Sync sync = new Sync(2);

    @Override
    public void lock() {
        sync.acquireShared(1);
    }

    @Override
    public void lockInterruptibly() throws InterruptedException {

    }

    @Override
    public boolean tryLock() {
        return false;
    }

    @Override
    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {
        return false;
    }

    @Override
    public void unlock() {
      sync.releaseShared(1);
    }

    @Override
    public Condition newCondition() {
        return null;
    }

    private static class Sync extends AbstractQueuedSynchronizer{
         Sync(int count){
               if (count < 0){
                   throw new IllegalArgumentException();
               }
               setState(count);
        }
        @Override
        protected int tryAcquireShared(int arg) {
            for (;;){
                int state = getState();
                int current = state - arg;
                if (current<0 || compareAndSetState(state,current)){
                    return current;
                }
            }
        }

        @Override
        protected boolean tryReleaseShared(int arg) {
               for(;;){
                   int state = getState();
                   int current = state + arg;
                   if (compareAndSetState(state,current)){
                       return true;
                   }

               }
        }
    }
}

```

 以上为自定义同步器

同一时刻只允许两个线程同时访问

### 可重入锁

重入锁ReentrantLock,顾名思义 代表一个线程可重复获取锁

Mutex自定义同步器的时候没有考虑到可重入锁

Synchronized关键字隐式的支持可重入

``` java
  public final boolean hasQueuedPredecessors() {
        // The correctness of this depends on head being initialized
        // before tail and on head.next being accurate if the current
        // thread is first in queue.
        Node t = tail; // Read fields in reverse initialization order
        Node h = head;
        Node s;
        return h != t &&
            ((s = h.next) == null || s.thread != Thread.currentThread());
    }
```

头节点不等于尾节点 返回true 

并且 后面的两个有一个为flase 才能进入if判断的CAS操作

所以头节点的下一个节点是空 或者 头节点的下一个节点的线程是当前线程返回false

```java
 protected final boolean tryAcquire(int acquires) {
            final Thread current = Thread.currentThread();
            int c = getState();
            if (c == 0) {
                if (!hasQueuedPredecessors() &&
                    compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(current);
                    return true;
                }
            }
            else if (current == getExclusiveOwnerThread()) {
                int nextc = c + acquires;
                if (nextc < 0)
                    throw new Error("Maximum lock count exceeded");
                setState(nextc);
                return true;
            }
            return false;
        }
```

### 公平锁和非公平锁

公平锁保证FIFO原则 即先进的队列先获取锁 不会出现一个多线程模式下一个线程重复的获取锁 

但是效率低 因为他会大量的切换线程

非公平锁不保证FIFO原则 即同一个线程反复获取锁的概率会很大 避免了线程的切换，节省时间

### 读写锁

之前的Mutex和ReentrantLock基本都是排他锁，也就是同一时刻只有一个线程进行访问

读写锁的好处是

当多个线程同时读的时候不阻塞 ，当其中一个线程写的时候 后续的线程不管是读操作还是写操作均阻塞，避免出现脏读现象

一般情况下，读写锁会比排他锁的性能好，因为一般场景下都是读多于写的

![image-20201125165901306](D:\学习笔记\image-20201125165901306.png)

锁降级，指的是当前线程先获取写操作的情况下再获取读锁之后释放写锁的情况 释放为读锁

ReadWriteLock()接口的实现部分API![image-20201125170657507](D:\学习笔记\image-20201125170657507.png)

``` java
package thread;

import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

/**
 * @program: dataStructure
 * @description:
 * @author: Mr.Feng
 * @create: 2020-11-25 17:09
 **/
public class Cache {
    private static Map<String,Object>  map = new HashMap<>();
    private static ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();
    private static Lock r = readWriteLock.readLock();
    private static Lock w = readWriteLock.writeLock();

    public static final Object get(String string){
        r.lock();
         try {
             return map.get(string);
         }finally {
             r.unlock();
         }
    }
    public static final void put(String str,Object obj){
        w.lock();
        try {
            map.put(str,obj);
        }finally {
            w.unlock();
        }
    }
    public static void clear(){
         w.lock();
         try {
              map.clear();
         }finally {
             w.unlock();
         }
    }
}

```

读写锁用于缓存 。Cache组合一个非线程安全的Map作为缓存的实现 

同时使用读写锁来保证Cache是线程安全的

### 位运算

">>>"无符号右移

操作规则：无论正负数，前面补零。

">>"右移

操作规则：正数前面补零，负数前面补1

"<<"左移

操作规则：无论正负数，后面补零。

``` java

public class BitmoveTest {
	public static void main(String args[]){
		
// >> 右移 前补符号位
		//>>相当于除2，左移相当于乘2
		int i=11; 
		int j=-13;
		System.out.println("右移，前面的位补符号位");
		//机器数值：0000 0000   0000 0000   0000 0000   0000 1011 
		//补码数值：0000 0000   0000 0000   0000 0000   0000 1011 
		//右移一位：0000 0000   0000 0000   0000 0000   0000 0101
		System.out.println("11>>1  的值为："+(i>>1));//结果为：5
		//机器数值：1000 0000   0000 0000   0000 0000   0000 1101 
		//补码数值：1111 1111   1111 1111   1111 1111   1111 0011 
		//右移一位：1111 1111   1111 1111   1111 1111   1111 1001（补码）
		//结果原码：1000 0000   0000 0000   0000 0000   0000 0111（-7）
		System.out.println("-13>>1 的值为："+(j>>1));//结果为：-7
		System.out.println("*************************************\n");
		
		System.out.println("左移，后面的位补零");
		//机器数值：0000 0000   0000 0000   0000 0000   0000 1011 
		//补码数值：0000 0000   0000 0000   0000 0000   0000 1011 
		//左移一位：0000 0000   0000 0000   0000 0000   0001 0110
		System.out.println("11<<1  的值为："+(i<<1));//结果为：22
		//机器数值：1000 0000   0000 0000   0000 0000   0000 1101 
		//补码数值：1111 1111   1111 1111   1111 1111   1111 0011 
		//左移一位：1111 1111   1111 1111   1111 1111   1110 0110（补码）
		//结果原码：1000 0000   0000 0000   0000 0000   0001 1010（-26）
		System.out.println("-13<<1 的值为："+(j<<1));//结果为：-26
		System.out.println("*************************************\n");
		
//>>>无符号右移 前补0
		System.out.println("无符号右移，前面补零");
		//机器数值：0000 0000   0000 0000   0000 0000   0000 1011 
		//补码数值：0000 0000   0000 0000   0000 0000   0000 1011 
		//右移一位：0000 0000   0000 0000   0000 0000   0000 0101
		System.out.println("11>>>1  的值为："+(i>>>1));//结果为：5
		//机器数值：1000 0000   0000 0000   0000 0000   0000 1101 
		//补码数值：1111 1111   1111 1111   1111 1111   1111 0011 
		//右移一位：0111 1111   1111 1111   1111 1111   1111 1001（补码也是原码）
		System.out.println("-13>>>1 的值为："+(j>>>1));//结果为：2147483641
		System.out.println("*************************************\n");
		
	}
}
```

无符号右移 >>> 无论正负数 高位补0

右移 >> 正数高位补0 负数高位补1

左移 <<  正负数后面均补0

### 读写锁二次

读写锁依赖自定义同步器来实现同步功能

读写状态就是其同步器的同步状态

回想ReentrantLock中自定义同步器的实现，同步状态表示锁的重入次数。

而读写锁的自定义5同步器需要在一个变量上代表读写两种状态 如何设计这两种状态就是关键

高16位低16位  高16位代表读锁的获取次数 低16位代表写锁的获取次数

判断写锁时 假设当前同步值为S  那么 S&0x0000FFFF 则会去掉高位，相当于写的状态

S>>>16位的值则就是读的状态 写状态+1则等于 S+1  读状态+1

![image-20201125212830920](D:\学习笔记\image-20201125212830920.png)

```java
protected final boolean tryAcquire(int acquires) {
 
            Thread current = Thread.currentThread();
            int c = getState();
            int w = exclusiveCount(c);
            if (c != 0) {
                // 1.写锁为0，读锁不为0    或者写锁不为0，且当前线程不是已获取独占锁的线程，锁获取失败
                if (w == 0 || current != getExclusiveOwnerThread())
                    return false;
                //2. 写锁数量已达到最大值，写锁获取失败
                if (w + exclusiveCount(acquires) > MAX_COUNT)
                    throw new Error("Maximum lock count exceeded");
                // Reentrant acquire
                setState(c + acquires);
                return true;
            }
            //3.当前线程应该阻塞，或者设置同步状态state失败，获取锁失败。
            if (writerShouldBlock() ||
                !compareAndSetState(c, c + acquires))
                return false;
            setExclusiveOwnerThread(current);
            return true;
        }
```

读锁的获取一般要判断写锁为0 如果getState不为0 但是写锁为0 代表读锁不为0 所以要返回False  同时判断当前线程如果不是已获取独占锁的线程，则也返回false 为什么呢？ 因为只有已获取锁的线程才可以重入的获取锁

原因在于读写锁要保证写锁对读锁的操作可见，如果允许读锁在已被获取的情况下被写锁获取 那么在同一时刻正在读的线程就无法感知到写线程的操作

写锁的释放和ReentrantLock基本类似 释放每次减掉1 当为0时读写线程可以继续访问	

上层同步器AQS提供了增加排他锁的队列和共享锁的队列 

下层各种实现的同步锁可以继承该类 实现AQS的作用推荐使用静态内部类的方式

相当于程序员只需要调用读写锁 而内部Sync静态内部类是实现同步的核心方法 对使用者隐藏其实现细节

​	![image-20201125221203576](D:\学习笔记\image-20201125221203576.png)

读锁的每次释放(线程安全的，可能有多个线程同时释放读锁)均减少读状态 减少的值是1<<16

### 锁降级

![image-20201125223005360](D:\学习笔记\image-20201125223005360.png)

### Condition

#### Condition的实现与分析

```java
        public final void await() throws InterruptedException {
            if (Thread.interrupted())
                throw new InterruptedException();
            Node node = addConditionWaiter(); //增加到等待队列
            int savedState = fullyRelease(node); //释放该线程获取的锁
            int interruptMode = 0;
            while (!isOnSyncQueue(node)) {//判断是否在同步队列中
                LockSupport.park(this); //进入等待状态 如果执行到下面的代码代表已经被唤醒
                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                    break;
            }
            if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
                interruptMode = REINTERRUPT;
            if (node.nextWaiter != null) // clean up if cancelled
                unlinkCancelledWaiters();
            if (interruptMode != 0)
                reportInterruptAfterWait(interruptMode);
        }

```

调用了上面方法的线程成功获取了锁的线程，也就是同步节点的首节点 

为什么呢？ 因为在调用Condition.await的前提是一定要先获取锁

而排他锁获取锁都是队列中的头节点获取锁， 线程进入同步队列的tail

头节点释放锁以后唤醒后继节点  

根据上图代码示意

首先该线程获取锁，也就是同步队列的首节点，该方法会将当前线程构造成节点并且加入等待队列 同时释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态

当等待队列中的节点被唤醒，则该节点开始尝试获取同步状态，如果发现不是调用了Condition.signal()方法被唤醒，而是对等待线程进行中断，则会抛出InterruptedExcepetion

![image-20201126164202833](D:\学习笔记\image-20201126164202833.png)

![image-20201126164226769](D:\学习笔记\image-20201126164226769.png)

同步器里面的可以有多个Condition 并且每个Conditot都会维护一个等待队列

同步队列的首节点并不会直接加入等待队列，而是通过addConditionWaiter方法构造一个Node节点加入到等待队列的队尾

#### Condition的唤醒

![image-20201126164845461](D:\学习笔记\image-20201126164845461.png)

调用Condtion.signal方法 会将等待队列的头结点唤醒，在唤醒结点之前，会将结点移到同步队列中

![image-20201126165331781](D:\学习笔记\image-20201126165331781.png)

被唤醒的等待队列通过enq方法加入到同步队列的尾部 然后当前线程使用LockSupport唤醒该节点的线程。

被唤醒后的线程从下面的循环退出 因为此使已经在同步队列了 该Node.condition已经改为Node.signal

```java
   while (!isOnSyncQueue(node)) {//判断是否在同步队列中
                LockSupport.park(this); //进入等待状态 如果执行到下面的代码代表已经被唤醒
                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                    break;
            }
```

所以会退出循环 进而调用同步器的acquireQueued方法加入到同步状态的竞争中

成功获取到锁以后该方法就会从await返回，表示此使该线程已经获取了锁

## JAVA并发容器和框架

### ConcurrentHashMap的实现原理与使用

为什么要使用该容器

因为hashMap不是线程安全的，在多线程环境下使用HashMap的put会引起死循环 导致CPU占用百分之百 

hashTable效率低下

![image-20201127170034939](D:\学习笔记\image-20201127170034939.png)

![image-20201127170054604](D:\学习笔记\image-20201127170054604.png)

### HashMap线程安全问题

jdk1.7并发会出现环形链表 在扩容的transfer代码下 将旧数据转移到新数据的时候会出现环形列表 死循环 

**hashMap的大概思路**

jkd1.7的时候

然后通过该值和数组长度做了一个hash运算 

得到对应桶的下标 

然后遍历该桶 看有没有相等的key 如果有 则覆盖vaule值

如果没有则 新增加一个节点

增加节点首先判断数组长度有没有超过阈值 threshold 如果超过 调用resize方法扩容原来的2倍

然后将原来数组的数据转移到该新数组 

然后 用数组长度*0.75 赋值给threshold

扩容的大概思路：

 **1.8下首先判断数据有没有超过threshold 如果有 则调用resize进行赋值 先插入后扩容**

**扩容整体思路根据是 将原有的容量*2 threshold扩容阈值也乘以2 然后遍历旧数组 拿出每个链表 判断如果没有发生冲突则直接根据 e.hash & (newCap -1) 选择桶位置放入 如果有发生冲突**

**则进行**

**定义两个链表 通过 e.hash&oldCap 判断到底是放入原索引还是新索引 如果是新索引则 是原索引+oldCap处**

**以上是对于使用默认构造器**

**首先判断有没有被扩容过，如果有 判断有没有到达临界值 如果没有 则扩大二倍**

**如果没有被扩容过  且threshold被构造器指定值** 

**如果没有被扩容过，且都为空 则赋默认值**

**下面代码则是指定初始值得到的** 

```java
 if (initialCapacity < 0)
            throw new IllegalArgumentException("Illegal initial capacity: " +
                                               initialCapacity);
        if (initialCapacity > MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        if (loadFactor <= 0 || Float.isNaN(loadFactor))
            throw new IllegalArgumentException("Illegal load factor: " +
                                               loadFactor);
        this.loadFactor = loadFactor;
        this.threshold = tableSizeFor(initialCapacity);
```



为什么是负载因为是0.75

因为他和扩容有关系  需要用长度*负载因子计算什么时候扩容最好

如果到1再扩容 可能冲突会非常多   如果太小 空间浪费  0.75 = 4分之三  又因为每次扩容是2的倍数 初始值是16  所以 任何情况下扩容 乘以 4分之三都是整数 也便于计算 

为什么每次扩容都是2的倍数呢？ 

因为让位置更均匀分布 2进制低位都是1可以使得不同的hashCode有不同的值

为什么与运算比模运算效率高?

因为与运算是直接对内存数据进行操作，不需要转成十进制

```java
X % 2^n = X & (2^n – 1)

2^n表示2的n次方，也就是说，一个数对2^n取模 == 一个数和(2^n – 1)做按位与运算 。

假设n为3，则2^3 = 8，表示成2进制就是1000。2^3 = 7 ，即0111。

此时X & (2^3 – 1) 就相当于取X的2进制的最后三位数。

从2进制角度来看，X / 8相当于 X >> 3，即把X右移3位，此时得到了X / 8的商，而被移掉的部分(后三位)，则是X % 8，也就是余数。
而且位运算还可以很好的解决负数问题hashcode的结果是int类型，而int的取值范围是-2^31 ~ 2^31 – 1
```

```java
h ^= k.hashCode();
h ^= (h >>> 20) ^ (h >>> 12);
return h ^ (h >>> 7) ^ (h >>> 4);
```

这段代码是给key进行扰动运算 尽可能的让低位不一致 频繁右移进行异或  该是在jdk1.7的时候

![image-20201130140351443](D:\学习笔记\image-20201130140351443.png)

为什么要用 (n-1) & hash 这个公式来计算位置呢?   

**因为要计算桶的位置  会有(n-1) & hash  又因为 (n-1) & hash = hash %n** 

**但是 &运算比 % 运算快 并且还要保证不超过桶的数量**  

  int h = 0; 

key =  (h = key.hashcode) ^ (h >>>16)

为什么拿到key之后首先让 key 的hashcode 和 hashcode值右移16位进行异或运算呢? 相当于低16位和高16位做了一个异或

 **主要是为了均匀分布** 为什么异或了以后就实现了均匀分布呢？

 //将旧链表的值转移到新链表 

```java
 while(e != null)

{

   Entry next = e.next;

​      e.next = newTable[i];  i 为桶的位置

​      newTable[i] = e;

​     e= next;

}
```

1.8的hashMap

问？ hashMap是先扩容还是先插入

答： 1.7的时候先扩容后插入 1.8的时候先插入后扩容

```java
https://blog.csdn.net/qq_36520235/article/details/82417949?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.control
```

### 1.8下的ConcurrentHashMap

不再使用分段锁概念，而是使用和HashMap一样的结构 数组+链表+红黑树 

首先和hashMap低高位异或，然后去符号 计算出桶的位置 判断桶位置的头节点hash>0如果大于再判断key是不是相等 如果相等则覆盖 如果不等 插入到链表后面 

然后判断需不需要转红黑树

如果hash小于0 则是对红黑树进行操作

put大致为分为三部分，初始化，扩容，帮助数据迁移

扩容也是大于8 但是他不一定会扩容成红黑树 如果数组长度小于64 则会选择扩容数组

### 1.7下的ConcurrentHashMap的源码

使用的是分段锁 segment[]数组

每个数组里面有hashEntry数组  hashEntry数组每个元素是数组+链表

![image-20201130170810809](D:\学习笔记\image-20201130170810809.png)

concurencyLevel是决定并发度，也就是决定segments数组的大小 ，每一个segment是继承了ReentrantLock 是一个可重入锁

在默认情况下该值等于16  则 sshift = 4; ssize = 16; segmentShift = 28;  segmentMask = 15

```java
private int hash(Object k) {
    int h = hashSeed;
 
    if ((0 != h) && (k instanceof String)) {
        return sun.misc.Hashing.stringHash32((String) k);
    }
 
    h ^= k.hashCode();
 
    // Spread bits to regularize both segment and index locations,
    // using variant of single-word Wang/Jenkins hash.
    h += (h <<  15) ^ 0xffffcd7d;
    h ^= (h >>> 10);
    h += (h <<   3);
    h ^= (h >>>  6);
    h += (h <<   2) + (h << 14);
    return h ^ (h >>> 16);
}
 
int j = (hash >>> segmentShift) & segmentMask;
```

可以看出和HashMap求hash方法如出一辙，只不过用一种变种的哈希算法，也是为了减少冲突

get操作不用加锁，用到了volatile定义需要读的变量 

![image-20201201101358455](D:\学习笔记\image-20201201101358455.png)

![image-20201201101410347](D:\学习笔记\image-20201201101410347.png)

 统计当前segment大小的count和HashEntry的value定义为volatile

put方法必须加锁，首先判断是否需要扩容，其次插入 

优于hashMap 因为hashMap先插入后扩容，可能插入后就不使用了造成了无效的扩容

#### size操作

如果要统计ConcurrentHashMap元素的大小，就必须统计所有segment里元素的大小后求和，segment里面count是一个volatile变量，是不是只需要把所有count加起来就可以了呢？ 不是的

因为count可能在累加的时候出错，最安全的做法是把所有的segment的put,remove,clean方法锁住，但是这显然比较低效

因为在累加过程中，出错的机率非常小，所有使用的是先在put,remve,clean方法使用后都会讲modcount变量+1 通过累加前后判断modcount是否变化来判断  尝试2次，如果都不一致则加锁

### HashTable

hashtable是直接取hashCode 和 int index = (hash & 0x7FFFFFFF) % tab.length;  这样求索引的

为什么要这样求? 因为hash有可能是负数 所以需要与0x7FFFFFFF 让最高位符号位为0 因为负数最高位是1  为什么在此处选用了 取模呢？ 因为HashTable的扩容机制和构造函数

hashTable的默认初始容量为11  每次扩容为2n+1

也就是说，hashTable的链表数组默认是一个素数，奇数 扩容之后也是一样

当hash表为素数时，简单的取模运算会使结果更加均匀，减少冲突

```java
https://blog.csdn.net/xu_dongdong/article/details/80251936  //参考大神博客
```

**1.8和上面的不同就是取消了hash方法**

**hashMap1.8只做了一次右移16位异或 而不像1.7做了多次 但是原理一致 都是为了分布均匀，使得低位尽可能的不一致 相当于低16位和高16位做了一个异或**

### CoucurrentLinkedQueue

![image-20201201115118022](D:\学习笔记\image-20201201115118022.png)

是一个链表队列 无界的 无阻塞 使用CAS算法完成

![image-20201201120144296](D:\学习笔记\image-20201201120144296.png)

可以看到tail节点不总是尾节点

首先初始情况下 Head等于空， tail = head 当第一个元素添加的时候 让head.next = 元素1节点 又因为tail = head 所以头尾节点都指向元素1

当第二个元素添加 首先让元素1的next节点指向元素2 然后更新元素2为tail节点

当第三个元素添加 让tail.next = 元素三

当第四个元素添加 让 元素三.next = 元素4 将元素4更新为tail节点

首先判断tail的next等不等于空，如果等于空。则将tail.next指向该元素

如果不等于空。 则拿出tail.next该元素 让tail.next.next = 添加的元素 然后更改尾节点

从源码角度分析，整个入队过程做了两件事，第一定义出尾节点，第二是使用CAS算法将入队节点设置成尾节点的next节点

#### 定义尾节点

tail节点并不总是尾节点。所以每次入队都需要tail来定义尾节点。尾节点可能是tail节点也可能不是，也可能是tail.next节点。

![image-20201201122940753](D:\学习笔记\image-20201201122940753.png)

![image-20201201122955233](D:\学习笔记\image-20201201122955233.png)

上面的代码一直在找尾节点并尝试修改尾节点的next节点

#### 出队

![image-20201201143200180](D:\学习笔记\image-20201201143200180.png)

首先每次取元素的时候先判断head是不是空，因为也不是每次都会更新head节点 

通过hops变量来减少CAS更新head节点的消耗，从而提升效率 从本质上来看就是增加volatile的读来减少volatile的写

如果head是空，也代表已经取过一次 然后拿到下一个节点，尝试使用cas将引用置为空，然后让该节点的next节点修改为head节点

## JAVA中的阻塞队列

## ArrayBlockingQueue

是一个由数组结构实现的有界阻塞队列

此队列按照先进先出的原则对元素进行排序

默认情况下是非公平的，可以指定为公平队列 但是可能效率低

## LinkedBlockingQueue

是一个用链表实现的无界阻塞队列，先进先出对元素进行排序

构造器指定大小则是有界

## PriorityBlockingQueue

是一个支持优先级排序的无界阻塞队列，默认情况下元素采用升序排列，也可以自定义实现compare to 来指定元素排序规则

## DelayQueue

是一个支持延迟获取元素的无界队列，队列使用PriorityBlockingQueue来实现，队列中的元素必须实现Delay接口

该队列非常有用，可以用在以下场景

 缓存系统的设计，定时任务调度

![image-20201201170637076](D:\学习笔记\image-20201201170637076.png)

![image-20201201172352191](D:\学习笔记\image-20201201172352191.png)

实现延时阻塞队列

leader变量是等待获取队列头部元素的线程

首先获取延时时间，如果没到时间则进入等待，如果leader是空则把当前线程赋值为leader并且进行延迟获取

## SynchronousQueue

是一个不存储元素的阻塞队列，每put一个元素必须等待take 否则不能继续put元素

支持公平访问队列，默认是非公平，非常适合传递性场景 吞吐量高于Array和Linked有界队列

## LinkedTransferQueue

链表结构的无界队列，相比于其他阻塞队列多了tryTranSfer和tranSfer方法

### transfer

该方法如果有当前消费者正在等待接受元素(消费者使用take或者带有时间限制的poll方法时)，transfer方法会立刻将元素传输给消费者，如果没有消费者等待消费，会将该元素修改为tail节点，并等待消费者消费，直到消费者消费了才返回

![image-20201201173844160](D:\学习笔记\image-20201201173844160.png)

第一行代码时尝试修改当前元素为tail节点

第二行代码是让CPU自旋等待消费者元素消费，因为自旋会消耗CPU，所以自旋一段时间后会Thread.yield方法暂停当前线程

### tryTranSfer

该方法是用来试探生产者传入的元素能否直接交给消费者消费 如果没有消费者等待接受元素就返回false 该方法如论如何都会立刻返回

带有参数指定时间的该方法会直接把生产者传入的元素交给消费者，如果没有超时还没消费元素则返回false，否则返回true

## LinkedBlockingDeque

是一个链表结构的双端阻塞队列

可以两端插入和移出元素 在对现场同时入队时，也就少了一半的竞争

增加了 addFirst,addLast,offerFirst,offerLast,peekFirst,peekLast等方法

## 阻塞队列的实现原理

ArrayBlockingQueue主要用到了LockSupport.part方法阻塞当前线程

该方法会调用unsafe.part(boolean isAbsolute,long time)  该方法是个native方法 

park方法会阻塞当前线程，直到出现下面四种情况会返回

1.线程被中断

2.等待时间结束

3.发生异常

4.与park对应的unpark执行或者已经执行时 已经执行是指先执行unpark再执行park

# Fork/Join框架

![image-20201201182211326](D:\学习笔记\image-20201201182211326.png)

本质就是将大任务转换为小任务让多个线程去执行，最后合并

## 工作窃取算法

假设我们做一个大任务，把该任务分为多个小任务，为了减少线程间的竞争 把小任务放到队列中并且为每一个队列提供一个线程  此时会出现某个线程执行完了 其他线程还在执行任务，工作窃取算法就是让该线程去给其他线程帮忙，所以使用的队列通常会是双端队列 也是为了减少线程之间的竞争 被窃取任务的线程永远在双端队列头部拿任务执行，窃取队列在尾部

优点：充分利用线程进行并行计算

缺点：在某些情况下还是存在竞争，比如双端队列只有一个任务时

该算法还会消耗更多的系统资源，比如创建多个线程。创建多个双端队列

## Fork/Join框架实现原理

ForkJoinPool是由ForkJoinTask数组和ForkJoinWorkerThread数组来完成的 ForkJoinTask负责将数据存放和提交给ForkJoinPool ForkJoinWorkerThread数组负责执行这些任务

### Fork原理

![image-20201201202327882](D:\学习笔记\image-20201201202327882.png)

putTask方法是将当前任务存放到ForkJoinTask数组里面，然后再调用ForkJoinPool的signalWork唤醒或者创建一个工作线程来完成该任务

![image-20201201202427625](D:\学习笔记\image-20201201202427625.png)

### Join原理

ForkJoin的join方法是阻塞当前线程并等待获取结果 

# JAVA中的16个原子操作类

Atomic包一个提供了三个类，属于4中类型的原子更新方式，分别是原子更新基本类型，原子更新数组。原子更新引用，原子更新属性

void lazySet(new Value) 最终会设置为new Value，使用lazySet设置值以后，允许其他线程在之后的一小段时间里面读到的是旧值

int getAndSet(new Value) 设置新值，返回旧值

**三个更新原子基本类型**的类为

AtomicInteger,AtomicBoolean,AtomicLong 

**通过原子类型更新数组** 该包提供4个类

AtomicIntegerArray  更新整型数组的元素

AtomicReferenceArray 更新引用数组的元素

AtomicLongArray 更新长整型数组的元素

**原子更新引用类型** 该包提供三个类

AtomicReference 原子更新引用类型

AtomicReferenceFieldUpdater 原子更新引用类型里的字段

AtomicMarkableReference 原子更新带有标记位的引用类型

**原子更新字段类**

AtomicIntergerFieldUpdater 原子更新整型字段的更新器

AtomicLongFieldUpdater 原子更新长整型字段的更新器

AtomicStampedReference 原子更新带有版本号的引用类型

该类可以将整数值和引用关联起来，可用于原子的更新数据和数据的版本号，可以解决使用CAS产生的版本号问题

以上是JDK1.7就已经存在的

JDK8时出现了4个原子操作类

分别是

DoubleAccumulator

DoubleAdder

LongAccumulator

LongAdder

AtomicLong高并发下多个元素自旋获取同一个原子变量 性能不好

LongAdder解决了高并发的问题 

LongAdder里面有三个值  base,cells[],cellsBusy  //用于保护，创建，扩容cells数组

base是在无竞争情况下使用 和AtomicLong一样 

如果出现竞争 会初始化cells数组 存入某个cell 求和的时候加上所有cell和base值

cells数组初始化长度为2，以后每次扩大2倍 最大为CPU的核心数，CPU能够并行的CAS操作的最大数量是他的核心数 cell也是一个hash表 每个线程会对cell[threadLocalRamdomProbe % cells.length] 上的value做累加

cellsBusy是防止多线程同时修改cells数组

0为无锁，1为加锁

cell数组扩容加锁，初始化加锁，如果cells数组中某个元素为null,给该位置创建cell对象的时候加锁

base同时也会在cells数组不可用的时候，会将值累加到base上

进入一下if的条件如果cells不等于空，则代表存在竞争 直接进入 或者如果cas更改base值失败 也进入 进入后判断数组是不是被初始化，同时判断cells数组上某个元素是不是为空，尝试更改某个元素上的value

```java
  if ((as = cells) != null || !casBase(b = base, b + x)) {
            //uncontended判断cells数组中，当前线程要做cas累加操作的某个元素是否#不#存在争用，如果cas失败则存在争用；uncontended=false代表存在争用，uncontended=true代表不存在争用。
            boolean uncontended = true;
            /**
            *1. as == null ： cells数组未被初始化，成立则直接进入if执行cell初始化
            *2. (m = as.length - 1) < 0： cells数组的长度为0
            *条件1与2都代表cells数组没有被初始化成功，初始化成功的cells数组长度为2；
            *3. (a = as[getProbe() & m]) == null ：如果cells被初始化，且它的长度不为0，则通过getProbe方法获取当前线程Thread的threadLocalRandomProbe变量的值，初始为0，然后执行threadLocalRandomProbe&(cells.length-1 ),相当于m%cells.length;如果cells[threadLocalRandomProbe%cells.length]的位置为null，这说明这个位置从来没有线程做过累加，需要进入if继续执行，在这个位置创建一个新的Cell对象；
            *4. !(uncontended = a.cas(v = a.value, v + x))：尝试对cells[threadLocalRandomProbe%cells.length]位置的Cell对象中的value值做累加操作,并返回操作结果,如果失败了则进入if，重新计算一个threadLocalRandomProbe；
            如果进入if语句执行longAccumulate方法,有三种情况
            1. 前两个条件代表cells没有初始化，
            2. 第三个条件指当前线程hash到的cells数组中的位置还没有其它线程做过累加操作，
            3. 第四个条件代表产生了冲突,uncontended=false
            **/
            if (as == null || (m = as.length - 1) < 0 ||
                (a = as[getProbe() & m]) == null ||
                !(uncontended = a.cas(v = a.value, v + x)))
                longAccumulate(x, null, uncontended);
        }

```

# JAVA的并发工具类

## 等待多线程完成的CountDownLatch

join就是让当前线程等待join线程结束，否则就让当前线程永远等待

```java
while(isAlive()){
    wait(0); //表示永远等待 
}
```

直接join线程终止后，线程的this.notifyAll方法会被调用。在JVM里面实现

![image-20201202143012787](D:\学习笔记\image-20201202143012787.png)

c.await()方法会阻塞当前线程 直到N等于0

## 同步屏障CyclicBarrier

字面意思就是可循环使用的屏障 ，要做的事情就是让一组线程到达一个屏障(同步点)时，被阻塞，直到最后一个线程到达后，屏障才会开门。所有被屏障拦截的线程继续执行

该构造参数传入一个int，参数表示想要拦截的线程数量 每个线程调用await方法表示我已经到达了同步点

该类还提供一个更高级的构造函数，CyclicBarrier(int parties,Runnable barrier-Action);

该方法会优先执行构造函数里面的程序、

应用场景 ： 多线程计算数据，最后合并结构的场景

## CountDownLatch和CyclicBarrier区别

前者的计算器只可以使用一次，后者可以使用reset()方法重置，后者更适合

更复杂的业务。后者还提供了一些其他有用的方法 比如 getNumberWaiting方法可以获得阻塞的线程数量等等 isBroken方法用来了解阻塞的线程是否被中断

## 控制并发数量的Semaphore

可以比作控制流量的信号灯，比如马路要控制流量 只允许有100辆车子在这条马路上行事，其他的车子必须在路口等待  此时前100辆车子会看到绿灯，后面的车子看到的是红灯。如果100辆有车子通过，则后面的车子可以加入 但是不能超过100辆

其中车就是线程，驶入马路就代表线程正在执行，等待的车子代表线程被阻塞，离开的车子代表线程执行完成

提供了acquire,release方法 获取许可证和释放许可证

intavailablePermits();返回此信号量中当前可用的许可证数

intgetQueueLength()；返回正在等待获取许可证的线程数

![image-20201202154221669](D:\学习笔记\image-20201202154221669.png)

## 线程间交换数据的Exchanger

是一个线程之间协作的工具类，用于线程之间的数据交换，提供一个同步点，两个线程可以交换彼此的数据 一个线程执行了exchager方法会一直等待第二个线程也执行exchager方法

当两个线程都达到同步点，就可以交换数据

```java
package tree;

import java.util.concurrent.Exchanger;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

/**
 * @program: dataStructure
 * @description:
 * @author: Mr.Feng
 * @create: 2020-12-02 15:55
 **/
public class Test {
    private static final Exchanger<String> exer = new Exchanger<>();
    private static ExecutorService service = Executors.newFixedThreadPool(30);
    public static void main(String[] args) {
          service.execute(() ->{
              try {
                  String a= "银行B的流水";
                  exer.exchange(a);
              } catch (InterruptedException e) {
                  e.printStackTrace();
              }
          });
          service.execute(()->{
              try {
                  String b ="银行B的流水";
                  String exchange = exer.exchange(b);
                  System.out.println(exchange);
                  System.out.println(exchange.equals(b));
              } catch (InterruptedException e) {
                  e.printStackTrace();
              }
          });

    }
}

```

# JAVA中的线程池

1.线程池判断**核心线程池**里面的线程是否都在执行任务，如果没有则创建一个工作线程执行任务

如果都在执行任务，则进入下个流程

2.判断工作队列有没有满，如果没满则放入工作队列那么线程获取队列中的任务执行。如果满了进入下个流程

3.判断**线程池**里面的线程是否都处于工作状态，如果没有则创建一个工作线程 如果有则交给饱和策略来处理这个任务

![image-20201202175111395](D:\学习笔记\image-20201202175111395.png)

![image-20201202180443229](D:\学习笔记\image-20201202180443229.png)

 ThreadPoolExecutor执行excute方法分为下面4中情况

1.如果当前线程数小于corePool数，则创建工作线程(需要获取全局锁)

2.如果当前线程数大于等于corePool数，则向阻塞队列里面添加

3.如果阻塞队列数满则创建新的线程来处理任务(需要获取全局锁)

4.如果创建后的线程数大于maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler的rejectedExecution方法

源码如下

![image-20201202182237046](D:\学习笔记\image-20201202182237046.png)

工作线程，线程池创建线程时，会将线程封装成工作线程Worker，Worker在执行的时候会不停的从工作队列里面获取任务来执行

![image-20201202182533336](D:\学习笔记\image-20201202182533336.png)

![image-20201202182539278](D:\学习笔记\image-20201202182539278.png)

首先执行execute方法时，如果要创建线程则会让创建后的线程来执行任务

之后会反复从队列中获取

## 线程池的使用和创建

我们可以通过ThreadPoolExecutor来创建一个线程池

```java
new ThreadPoolExecutor(corePoolSize,maximumPoolSize,keepAliveTime,milliseconds,runnableTask,handler)
```

1.keepAliveTime 线程活动保持时间，线程池的工作线程活动后，保持存货的时间

2.runnbaleTaskQueue(任务队列)

​     2.1  ArrayBlockingQueue

​      2.2 LinkedBlockingQueue 该队列吞吐量高于数组队列，静态方法Executor.newFixedThreadPool()方法就使用了该队列

​     2.3 SynchronousQueue 不存储元素的队列 Executor.newCachedThreadPool()方法就使用该队列

   3 maximumPoolSize 注意 如果是无界队列 那么该数的设置就没有意义

4 ThreadFactory: 用户创建线程的工厂，可以给线程创建出有意义的名字   用开源框架guava提供的ThreadFactoryBuilder可以快速的给线程设置有意义的名字

![image-20201203101948642](D:\学习笔记\image-20201203101948642.png)

5.RejectedExecutionHandler(饱和策略) 当任务队列和线程池都满了，那么要采取该策略 

 **默认采用abortPolicy 中止策略** 

  **有以下四种策略 AbortPolicy,CallerRunsPolicy 只用调用者所在的线程来执行任务** 

​                             **DiscardOldestPolicy 丢弃任务队列最早的任务**

​                            **DiscardPolicy 丢弃任务 不处理**

**当然，也可以实现RejectedExecutionHandler接口自定义策略，如记录日志和持久化该任务**

## 关闭线程池

可以调用线程池的shutdown方法和shutdownNow方法 原理都是遍历工作线程然后调用线程的中断方法interrupt方法来中断线程

但是他们有一定区别 shutdown是将线程池的状态设置为SHUTDOWN，并中断所有没有执行任务的线程

 shutdownNow是将线程池的状态设置为STOP，尝试停止所有正在执行或者暂停任务的线程，并返回等待执行任务的列表

这两个方法是要调用任意一个 isShutDown方法都会返回true,直到所有任务都关闭 isTerminaed 是否结束 该方法才会返回true。

## 合理地配置线程池

要想合理的配置线程池，可以从以下角度来分析

任务的性质：CPU密集型任务，IO密集型任务，混合型任务

CPU密集型任务：是指大量需要CPU计算的任务，不建议CPU切换线程，因为会浪费大量的时间 所以一般密集型任务线程池大小推荐使用 CPU核心数+1的线程数量

IO密集型任务：CPU通常会一直等待IO操作完毕，因为IO的速度远远小于CPU的速度 用于网络，磁泡IO 为了提升CPU的利用率 推荐使用 CPU核心数*2

任务的优先级：高，中，低；

任务的执行时间：长，中，短

任务的依赖性：是否依赖其他资源，如数据库连接

混合型任务可以进行拆分，拆分为CPU密集型任务和IO密集型任务

优先级的可以使用 优先级队列 PriorityBlockingQueue 注意 如果一直有优先级高的任务提交 那么低的任务不会执行

执行时间 也可以使用优先级队列 让执行时间短的先执行

依赖性，因为CPU向数据库提交数据或者查询数据 需要数据库响应 可能会比较慢，所以这种推荐将线程池的线程数设置较大

建议使用有界队列

## 线程池的监控

如果系统中大量使用线程池，则有必要对线程池进行监控，可以通过线程池提供的参数来进行监控

  taskCount : 线程池需要执行的任务数量

 completedTaskCount ：  线程池已完成的任务数量

largestPoolSize : 线程池最大的数量 可以判断有没有满过

getPoolSize : 线程池的线程数量 只增不减

getActiveCount 获取活动的线程数量

也可以根据执行任务前，后，完成来执行代码建龙

protected void beforeExecute();

# CopyOnWriteArrayList源码

采用的写时复制策列，添加元素或者修改元素的时候都要创建一个数组长度的副本进行修改

![image-20201203154005874](D:\学习笔记\image-20201203154005874.png)

```java
    public boolean add(E e) {
        final ReentrantLock lock = this.lock;
        lock.lock();		//先加锁
        try {
            Object[] elements = getArray();
            int len = elements.length;
            Object[] newElements = Arrays.copyOf(elements, len + 1);		//复制到新数组中
            newElements[len] = e;		//在新数组中添加元素
            setArray(newElements);		//将元素设置为新数组
            return true;
        } finally {
            lock.unlock();
        }
    }

```

就是取到原有的数组 然后copy一份长度加1的数组 将新元素添加到元素的末尾

底层是System.arraycopy方法  本地方法

获取指定位置元素

```java
	public E get(int index) {
        return get(getArray(), index);
    }
	
	final Object[] getArray() {
        return array;
    }

	private E get(Object[] a, int index) {
        return (E) a[index];
    }

```

上面是线程不安全的 

因为他分为两步 第一步获取数组 第二步获取指定位置上的数据 如果线程A获取数组后，线程B修改了数据 那么线程A拿到的数据就是旧的 这就是**写时复制策略**产生的弱一致性问题

修改元素

```java
    public E set(int index, E element) {
        final ReentrantLock lock = this.lock;
        lock.lock();		//加锁
        try {
            Object[] elements = getArray();
            E oldValue = get(elements, index);		//先得到要修改的旧值

            if (oldValue != element) {				//值确实修改了
                int len = elements.length;
                //将array复制到新数组，并进行修改，并设置array为新数组
                Object[] newElements = Arrays.copyOf(elements, len);			
                newElements[index] = element;
                setArray(newElements);
            } else {
                // 虽然值确实没改，但要保证volatile语义，需重新设置array
                setArray(elements);
            }
            return oldValue;
        } finally {
            lock.unlock();
        }
    }

```

可以看到也是先copy一份新数组 然后将新数组的指定元素修改

```java
    public static void main(String[] args) {
        CopyOnWriteArrayList<String> arrayList = new CopyOnWriteArrayList<>();
        arrayList.add("hello");
        arrayList.add("alibaba");

        Iterator<String> itr = arrayList.iterator();
        while (((Iterator) itr).hasNext())
            System.out.println(itr.next());
    }

```

弱一致性的迭代器 

调用iterator方法的时候会给数组快照和数组下标复赋值

然后迭代的时候如果其他线程修改该list 那么迭代器是不可见的 为什么呢？ 

因为修改的时候会copy一份新数组 旧数组被丢掉  snapshot还是指向旧数组，array变量已经指向新数组

```java
    static final class COWIterator<E> implements ListIterator<E> {
        /** 数组array快照 */
        private final Object[] snapshot;
        /** 数组下标  */
        private int cursor;

        private COWIterator(Object[] elements, int initialCursor) {
            cursor = initialCursor;
            snapshot = elements;
        }

        public boolean hasNext() {
            return cursor < snapshot.length;
        }

        @SuppressWarnings("unchecked")
        public E next() {
            if (! hasNext())
                throw new NoSuchElementException();
            return (E) snapshot[cursor++];
        }

```

# Executor框架

## Executor的两级调度机制

在HotSopt VM中，java的每个线程对应一个本地操作系统线程  在终止线程的时候，操作系统线程也会被回收 操作系统调度所有可用的线程并且给他们分配可用的CPU

在上层 JAVA多线程通常将大任务拆分为多个小任务然后执行  然后用户级的调度器(Executor框架)将多个任务映射为固定数量的线程

在下层 操作系统内核直接将操作系统线程映射到硬件处理器上 

![image-20201203171757258](D:\学习笔记\image-20201203171757258.png)

## Executor框架的结构

主要分为三大类 

​         任务 ： 主要分为Runnable,Callable两个接口  两个区别是Runnable没有返回值并且不能抛异常

​        任务的执行：任务执行机制的核心接口Executor,和子接口ExecutorService。ScheduleThreadPoolExecutor(用来执行周期任务的),ThreadPoolExecutor(线程池的核心实现类) 两个关键类

​        异步计算的结构：Future接口和FutureTask类

![image-20201203172402068](D:\学习笔记\image-20201203172402068.png)

虚线为实现 实线为继承

![image-20201203172424869](D:\学习笔记\image-20201203172424869.png)

## Executor的成员

1）ThreadPoolExecutor  通常使用Excutors工厂类来创建，可以创建三种 

FixedThreadPoolExecutor,CachedThreadPoolExecutor,SingleThreadPoolExcutor

下面分别介绍这三种 

​      1）FixedThreadPoolExecutor 创建一个固定大小的线程数量 使用的是无界队列

```java
return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue<Runnable>());
```

![image-20201203172940882](D:\学习笔记\image-20201203172940882.png)

适用于负载比较重的服务器，比如任务需要多线程大量计算 可以创建和CPU核心数+1的线程数量

2）SingleThreadPoolExecutor 

​    创建只有一个线程数量的线程池  适用于需要保证任务执行顺序

```java
    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue<Runnable>()));
    }
```

3）CachedThreadPoolExecutors 

创建一个无界的线程池，队列使用的是不存储元素的队列 

```java
  return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue<Runnable>());
```

表示线程获取任务最多等待60秒 否则终止该线程



2） Runnable和Callable接口

![image-20201203173629934](D:\学习笔记\image-20201203173629934.png)

callable方法

上面的如果调用FutureTask.get()方法会返回空  下面的会返回result对象

## ThreadPoolExecutor详解

### FixedThreadPool

![image-20201203173944666](D:\学习笔记\image-20201203173944666.png)

当主线程执行任务的时候 首先会判断当前线程池数量是不是小于corePool 如果是则创建新的工作线程 让新线程来执行任务 如果不小于 则加入无界队列

1）当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中的线程数不会超过corePoolSize。

2）由于1，使用无界队列时maximumPoolSize将是一个无效参数。

3）由于1和2，使用无界队列时keepAliveTime将是一个无效参数。

4）由于使用无界队列，运行中的FixedThreadPool（未执行方法shutdown()或shutdownNow()）不会拒绝任务（不会调用RejectedExecutionHandler.rejectedExecution方法）。 可能会导致内存溢出，因为无界队列一直会频繁的加任务，队列不会满 所以也不会拒绝任务抛出异常

### SingleThreadPoolExecutor

![image-20201203174358568](D:\学习笔记\image-20201203174358568.png)

### CachedThreadPool

1.该线程池执行任务时，首先会调用不存储元素队列offer方法向队列中添加元素，如果此时刚好有空闲线程执行poll方法 则刚好对应 否则如下

2.如果没有空闲线程 则创建一个工作线程 excute方法执行完成

3.工作线程调用队列中的poll方法 最多等待60S 如果还没有主线程提交任务 则终止该线程、

如果60秒内有主线程提交  则执行步骤1 

![image-20201203174918350](D:\学习笔记\image-20201203174918350.png)

SynchronousQueue 不存储元素队列 每个插入必须等待线程取出

![image-20201203174940270](D:\学习笔记\image-20201203174940270.png)

## ScheduledThreadPoolExecutor

![image-20201203195038547](D:\学习笔记\image-20201203195038547.png)

主线程调用如图两个方法会向DelayQueue队列添加一个实现了RunnableScheduleFuture接口的FutureTask 

为了实现周期性的执行任务 做了以下修改

使用DelayQueue队列 支持延时的提交任务 

获取任务的方式不同

### 其实现

有三个主要变量  long time : 表示下次要执行的时间   long period 表示任务的周期时间

​                         long sequenceNumber 表示任务被添加到ScheduleThreadPoolExecutor的序号

DelayQueue里面是一个优先级队列 PriorityQueue 该队列会按照time来排序 时间短的先执行 如果两个time相等 则按序号排 序号小的先执行

![image-20201203195705747](D:\学习笔记\image-20201203195705747.png)

![image-20201203195941149](D:\学习笔记\image-20201203195941149.png)

![image-20201203195950968](D:\学习笔记\image-20201203195950968.png)

![image-20201203195955993](D:\学习笔记\image-20201203195955993.png)

大致分为三部

获取锁， 判断条件 

加入队列

释放锁

![image-20201203200021115](D:\学习笔记\image-20201203200021115.png)

![image-20201203200025757](D:\学习笔记\image-20201203200025757.png)

获取锁

增加任务到队列

判断是不是头元素 如果是则唤醒所有等待的线程

## FutuerTask详解

Future接口和实现Future接口的FutureTask类代表异步计算的结果

FutrueTask类实现了Runnable接口，因此可以直接交给Executor执行

根据FutureTask.run方法的时机，可以处于三种状态

1）未启动，FutureTask.run方法未执行

2）已启动    FutureTask.run方法已启动

3）已完成    FutureTask执行完成后正常结束，调用FutureTask.cancel取消 和抛出异常而异常结束![image-20201204100806165](D:\学习笔记\image-20201204100806165.png)

当线程处于未启动状态下调用FutureTask.get()方法 会阻塞，调用cancel就不会执行此任务，在已启动状态下会阻塞当前线程直到任务执行完毕，执行FutureTask.cancel(true)方法将以中断的方式来停止此任务 当已完成的状态执行FureTask.cancle会返回false

![image-20201204101051747](D:\学习笔记\image-20201204101051747.png)

当一个线程需要等待另外一个线程把某个任务执行完成它才能继续执行 此时可以用FutureTask

多个线程试图执行同一任务时，只允许一个线程执行![image-20201204104038758](D:\学习笔记\image-20201204104038758.png)

![image-20201204104047833](D:\学习笔记\image-20201204104047833.png)

![image-20201204104842680](D:\学习笔记\image-20201204104842680.png)

上述代码如果线程1在执行1.3后线程2执行

假设第一次为空，则线程1创建任务1并且放入map，然后线程1执行任务1 此时线程2从map中获取相等的任务名 此时也就是任务1 因为线程1也在执行任务1  所以线程2只能等线程1完成 以此类推

就实现了多个线程只能执行一个任务的场景

## FutureTask实现

JDK1.7依赖AQS来实现 	1.8不再依赖AQS来实现 	而是通过一个volatile变量state以及CAS操作来实现

### JDK7的实现

是依赖AQS同步框架来实现，可重入锁ReentrantLock,ReentrantReadWriteLock,Semaphore,CountDownLatch 都是依赖AQS的

每一个基于AQS的同步器都会至少包含两种类型的操作 如下：

 	至少一个acquire ： 这个操作阻塞线程，除非AQS的状态允许 FutureTask的acquire操作作为get方法调用

​    至少一个release ： 这个操作改变AQS的状态，改变后的状态可允许一个或者多个阻塞线程解除阻塞 包含run,cancel方法

![image-20201204112604948](D:\学习笔记\image-20201204112604948.png)

1）FutureTask.get()方法会调用AQS的acquireSharedInterruptibly()(int arg)方法 该方法会调用FutureTask内部类Sync重写的tryAcquireShared判断操作是否成功，成功的条件为state=Run或者Cancel且runnable为空

2）如果失败则进入等待队列等待其他线程relase方法唤醒其后继线程(会级联唤醒)

run方法执行流程如下：

1）执行构造函数中指定的任务(Callbale.call)

2）以原子方式修改state状态为Run,如果修改成功把callable.call的返回值返回 然后调用AQS的releaseShred方法该方法会调用子类Sync的tryRelaseShared(arg)方法 会将runnable设置为空，返回ture

![image-20201204114405805](D:\学习笔记\image-20201204114405805.png)

当线程E执行Run方法时，会唤醒队列中第一个线程A，线程A被唤醒后首先从队列中删除然后唤醒B 以此类推

state表示了不同的状态(1 正在运行 2：表示运行完毕 4：表示任务取消)

调用get()方法会判断state状态 如果正在运行则阻塞，如果运行完毕则返回结果 如果任务取消则抛出异常

AQS的state可以干很多事情。比如说可重入锁的state用来判断重入的次数 同时只允许一个线程

Semaphore的state就是用来计算有多少个线程在执行

FutureTask的state就是用来判断处于那种状态  相当于共享锁，允许多个线程同时等待任务的结果 唤醒的时候会唤醒等待队列的所有线程来获取任务的结果

# 生产者和消费者

![image-20201204141619608](D:\学习笔记\image-20201204141619608.png)

首先启动一个生产者把所有邮件加入阻塞队列 消费者启动corePoolSize个线程处理邮件

![image-20201204141734197](D:\学习笔记\image-20201204141734197.png)

![image-20201204141743511](D:\学习笔记\image-20201204141743511.png)

![image-20201204141750478](D:\学习笔记\image-20201204141750478.png)

![image-20201204141801529](D:\学习笔记\image-20201204141801529.png)

![image-20201204141806423](D:\学习笔记\image-20201204141806423.png)

线程池就相当于一个生产者和消费者 只不过更加高明

生产者提交数据到线程池 如果不够corePoolSize则创建线程 否则直接扔到阻塞队列

比如上传文件附件系统 把文件上传需要很长时间 可以让用户把文件上传以后直接返回上传成功 把任务放到阻塞队列由消费者去完成任务

# 异步任务线程池

java线程池设计的非常巧妙，但是在某些场景下需要扩展 如果一个任务扔进线程池，但是运行的线程池重启了，导致任务丢失。 或者还有线程池只能处理本机的业务，在集群部署下不能有效的调度所有机器的任务

![image-20201204151549559](D:\学习笔记\image-20201204151549559.png)

结合线程池开发一个异步任务池

任务池的主要流程是，每台机器启动一个任务池，每个任务池里有多个线程池 

任务池会将该任务保存到数据库中，其他机器的任务池从数据库获取执行任务

每个任务有下列几点状态：创建(NEW)  ：提交给任务池的任务

 执行中(EXECUTING)  ：任务池从数据库拿到任务时的状态

RETRY(重试)   当执行任务出错时，程序显示的告诉任务池这个任务需要重试 

挂起(SUSPEND) ：当一个任务的执行依赖其他任务时，可以先挂起该任务

中止(TEMINER)：任务执行失败，让任务池停止执行该任务  

执行完成(FINISH) ：成功

**如果任务类型特别多 建议采用优先级的方式来隔离**

**因为会有高低优先级之分 时间短的任务特别多 可能时间长的就没法执行  所以必须隔离**

​	